import torch
from transformers import LlamaForCausalLM, AutoTokenizer
from datasets import load_dataset
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score
import logging
import argparse
from sklearn.model_selection import train_test_split
from torch.nn import functional as F
from torch.optim import AdamW
from tqdm import tqdm
import matplotlib.pyplot as plt
from torch.cuda.amp import autocast, GradScaler

# Initialize logging
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

def load_model_and_tokenizer(model_name: str, device: str):
    """Load the LLaMA model and tokenizer."""
    try:
        logger.info(f"Loading {model_name}...")
        tokenizer = AutoTokenizer.from_pretrained(model_name)
        model = LlamaForCausalLM.from_pretrained(
            model_name, 
            device_map="auto" if device == "cuda" else None,
            load_in_8bit=False,
            torch_dtype=torch.float32  # Use float32 for all parameters
        )

        if tokenizer.pad_token is None:
            tokenizer.pad_token = tokenizer.eos_token
            logger.info("Setting pad_token to eos_token.")
        
        model.config.pad_token_id = tokenizer.pad_token_id
        
        if device == "cpu":
            model = model.to(device)
        else:
            # Ensure the model is using float32 parameters
            model = model.float()
        
        return model, tokenizer
    except Exception as e:
        logger.error(f"Error loading model {model_name}: {str(e)}")
        raise

def prepare_input(text: str, label: str, tokenizer: AutoTokenizer):
    """Prepare input for the model."""
    prompt = f"Is the following text human-written or AI-generated? Text: '{text}'. Reply with '{label}'."
    inputs = tokenizer(prompt, return_tensors="pt", truncation=True, max_length=512, padding=True)
    return inputs

def train_model(model: torch.nn.Module, tokenizer: AutoTokenizer, train_data, val_data, num_epochs: int, learning_rate: float, device: str, batch_size: int, gradient_accumulation_steps: int):
    """Train the model using direct fine-tuning with memory optimizations."""
    model.train()
    optimizer = AdamW(model.parameters(), lr=learning_rate)
    scaler = GradScaler()
    
    train_losses = []
    val_losses = []
    
    for epoch in range(num_epochs):
        total_loss = 0
        optimizer.zero_grad()
        
        for i, (text, label) in enumerate(tqdm(train_data, desc=f"Epoch {epoch+1}/{num_epochs}")):
            inputs = prepare_input(text, "real" if label == "human" else "fake", tokenizer)
            inputs = {k: v.to(device) for k, v in inputs.items()}

            # Forward pass with mixed precision
            with autocast(enabled=device=="cuda"):
                outputs = model(**inputs, labels=inputs["labels"])
                loss = outputs.loss / gradient_accumulation_steps

            # Backward pass with gradient scaling
            scaler.scale(loss).backward()

            if (i + 1) % gradient_accumulation_steps == 0:
                scaler.unscale_(optimizer)
                torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)
                scaler.step(optimizer)
                scaler.update()
                optimizer.zero_grad()

            total_loss += loss.item() * gradient_accumulation_steps

        avg_train_loss = total_loss / len(train_data)
        train_losses.append(avg_train_loss)
        
        # Validate on validation set
        val_loss = validate_model(model, tokenizer, val_data, device, batch_size)
        val_losses.append(val_loss)
        
        logger.info(f"Epoch {epoch+1} completed. "
                    f"Train Loss: {avg_train_loss:.4f}, "
                    f"Val Loss: {val_loss:.4f}")

    plot_losses(train_losses, val_losses)
    return model

def validate_model(model: torch.nn.Module, tokenizer: AutoTokenizer, val_data, device: str, batch_size: int):
    """Validate the model on a validation set."""
    model.eval()
    total_loss = 0
    
    with torch.no_grad():
        for i in range(0, len(val_data), batch_size):
            batch = val_data[i:i+batch_size]
            texts, labels = zip(*batch)
            
            inputs = [prepare_input(text, "real" if label == "human" else "fake", tokenizer) for text, label in zip(texts, labels)]
            input_ids = torch.cat([input['input_ids'] for input in inputs], dim=0).to(device)
            attention_mask = torch.cat([input['attention_mask'] for input in inputs], dim=0).to(device)

            outputs = model(input_ids=input_ids, attention_mask=attention_mask, labels=input_ids)
            loss = outputs.loss
            total_loss += loss.item() * len(batch)

    avg_loss = total_loss / len(val_data)
    return avg_loss

def plot_losses(train_losses, val_losses):
    """Plot training and validation losses."""
    plt.figure(figsize=(10, 5))
    plt.plot(train_losses, label='Training Loss')
    plt.plot(val_losses, label='Validation Loss')
    plt.xlabel('Epoch')
    plt.ylabel('Loss')
    plt.title('Training and Validation Loss Over Time')
    plt.legend()
    plt.savefig('loss_plot.png')
    logger.info("Loss plot saved as 'loss_plot.png'")

def evaluate_model(model: torch.nn.Module, tokenizer: AutoTokenizer, test_data, device: str, batch_size: int):
    """Evaluate model on the test set and compute various metrics."""
    model.eval()
    all_preds = []
    all_labels = []

    with torch.no_grad():
        for i in range(0, len(test_data), batch_size):
            batch = test_data[i:i+batch_size]
            texts, labels = zip(*batch)
            
            inputs = [prepare_input(text, "real" if label == "human" else "fake", tokenizer) for text, label in zip(texts, labels)]
            input_ids = torch.cat([input['input_ids'] for input in inputs], dim=0).to(device)
            attention_mask = torch.cat([input['attention_mask'] for input in inputs], dim=0).to(device)

            outputs = model(input_ids=input_ids, attention_mask=attention_mask)
            logits = outputs.logits[:, -1, :]
            predicted_tokens = torch.argmax(logits, dim=-1)
            predicted_words = tokenizer.batch_decode(predicted_tokens.unsqueeze(-1), skip_special_tokens=True)
            predictions = [1 if word.strip() == "real" else 0 for word in predicted_words]

            all_preds.extend(predictions)
            all_labels.extend([1 if label == "human" else 0 for label in labels])

    accuracy = accuracy_score(all_labels, all_preds)
    precision = precision_score(all_labels, all_preds, average='binary')
    recall = recall_score(all_labels, all_preds, average='binary')
    f1 = f1_score(all_labels, all_preds, average='binary')

    logger.info(f"Test Accuracy: {accuracy:.4f}")
    logger.info(f"Test Precision: {precision:.4f}")
    logger.info(f"Test Recall: {recall:.4f}")
    logger.info(f"Test F1 Score: {f1:.4f}")

    return accuracy, precision, recall, f1

def main(args):
    device = "cuda" if torch.cuda.is_available() and not args.cpu else "cpu"
    logger.info(f"Using device: {device}")

    # Load model and tokenizer
    model, tokenizer = load_model_and_tokenizer(args.model_name, device)

    # Load AI text detection dataset
    dataset = load_dataset("artem9k/ai-text-detection-pile", split="train")
    logger.info(f"Loaded dataset with {len(dataset)} samples.")

    # Convert dataset to a list and take only 20,000 samples
    dataset_list = list(zip(dataset['text'], dataset['source']))[:5000]

    # Split the data into train/val/test sets
    train_data, temp_data = train_test_split(dataset_list, test_size=0.4, random_state=args.seed)
    val_data, test_data = train_test_split(temp_data, test_size=0.5, random_state=args.seed)
    logger.info(f"Training on {len(train_data)} samples, validating on {len(val_data)} samples, testing on {len(test_data)} samples.")

    # Train the model
    model = train_model(model, tokenizer, train_data, val_data, args.num_epochs, args.learning_rate, device, args.batch_size, args.gradient_accumulation_steps)

    # Evaluate model on the test set
    accuracy, precision, recall, f1 = evaluate_model(model, tokenizer, test_data, device, args.batch_size)

if __name__ == "__main__":
    parser = argparse.ArgumentParser(description="LLaMA Fine-tuning with FP32 Gradients")
    parser.add_argument("--model_name", type=str, default="meta-llama/Llama-3.2-1B", help="Name of the model to use")
    parser.add_argument("--seed", type=int, default=42, help="Random seed for reproducibility")
    parser.add_argument("--num_epochs", type=int, default=3, help="Number of training epochs")
    parser.add_argument("--learning_rate", type=float, default=1e-5, help="Learning rate for optimization")
    parser.add_argument("--batch_size", type=int, default=1, help="Batch size for training and evaluation")
    parser.add_argument("--gradient_accumulation_steps", type=int, default=8, help="Number of steps to accumulate gradients")
    parser.add_argument("--cpu", action="store_true", help="Use CPU instead of GPU")
    args = parser.parse_args()

    main(args)
